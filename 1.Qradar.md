# Protecting Openshift Security Cluster
## Part 1. Forwarding audit logs to Qradar

Be it for compliance, troubleshooting or due to purely security purposes, forwarding Openshift audit logs to Qradar will allow you to keep a reliable trail of key interactions with the Kube API, for example pods being created, secret being accessed, or the permissions of a user modified.
<br>
After a suspected attack or unplanned change, having access to such source of data will allow you identify who, when and what, and understand what exactly has happened.
<br>
This guide will show you how to set up this valuable integration, and the whole process, if you are lucky, shouldn't take more than a few hours.

```
NOTE: The guide has been developed based on Openshift Container Platform 4.9 and 4.10 and doesn't apply to managed Openshift deployments.
Audit logging and forwarding on managed environments like Azure ARO, AWS ROSA or IBM ROKS have each their own requirements so please refer to provider documentation, as this definitely won't work.
For OCP 4.6-4.8, this guide will apply for the most apart, with the only exception being the audit 'group' scope configuration of point 2.1 which won't be supported.
```

<br>

### Activities
#### 1. Qradar configurations
- 1.1 Creating Log Sources
- 1.2 Increasing Event size limit
#### 2. Openshift configurations
- 2.1 Enabling Audit logs
- 2.2 Installing Logging Operators
- 2.3 Deploying an instance of Logging Operator
- 2.4 Deploying an instance of Logging Forwarder Operator
#### 3. Qradar optional activities
- 3.1 Refine DSM
- 3.2 Estimate EPS

<br>

## 1. Qradar configurations
### 1.1 Creating Log Sources
For Qradar to parse the events sent by Openshift we need to deploy log sources with the appropiate DSM (Device Support Module). A DSM is a product specific plugin that allows Qradar to interpret the events being received. Unfortunately, an Openshift specific DSM doesn't yet exists, but we can use the **Kubernetes Audit** DSM instead which will work just fine.

<br>

The following configuration will bind the master nodes hostnames with the Kubernetes Audit DSM.

1. In the Qradar Console, go to *Admin*
2. Click on *Log Sources* (Under Data Sources), this will launch the Log Sources application.
3. Click on *Manage Log Sources*
4. On the top right, click on the plus button *New Log Source*
5. Click on *Multiple Log Sources*
6. Select *Kubernetes Audit* as the log source type
7. Select *Syslog* as the protocol
8. Leave Log Source parameters as default.
9. Leave Common Protocol Parameters as default.
10. Select Manual, and input the hostnames of your master nodes, 1 by 1. Then click Finish.

![image](https://user-images.githubusercontent.com/75438200/165949068-29507d68-af4f-4a60-b0b0-e44350faef33.png)

<br>

### 1.2 Increasing event limit size

Usually a log from Openshift will weight about 2KB, but it could also get significantly bigger than that, for example when you deploy a complex resource on OCP as the whole yaml content will be audited.
To avoid important events being dropped at Qradar, we are going to increase the event size. The maximum is 32KB.

1. In the Qradar Console, got to *Admin*
2. Click on *System Settings* (Under System Configurations)
3. Click on the *Advanced* button to display additional configuration fields.
4. Set the *Max UDP Syslog Payload Length* to your desired limit. In this case we are doing 32000.

![image](https://user-images.githubusercontent.com/75438200/165949967-46e3c2e2-24b0-4427-afc5-4b4e8fa4b0e9.png)


<br>

## 2. Openshift Configuratoins
### 2.1 Enabling audit logs
To enable audit logs we need to modify the apiserver cluster resource

1. Run ` oc edit apiserver cluster` to edit the apiserver cluster resource.
2. Configure the audit policy as per your requirements. Check the examples below for reference. 

Example 1: Audit API requests **ONLY** from users members of the *exampleg* group.
```
apiVersion: config.openshift.io/v1
  kind: APIServer
  metadata:
  ...  
  spec:
    audit:
      customRules:
        - group: exampleg
          profile: WriteRequestBodies
      profile: None
```
<br>

Example 2: Audit API requests from every user.
```
apiVersion: config.openshift.io/v1
  kind: APIServer
  metadata:
  ...  
  spec:
    audit:
      profile: WriteRequestBodies
```
3. Making a change here will force the kubeapi pods to be restarted, which could take a few minutes. Audit logs will be created at the local disk of the master nodes. <br>
You could verify this manually with `oc adm node-logs <node_name> --path=kube-apiserveraudit.log `

<br>

### 2.2 Installing Logging Operators
Audit logs are stored locally at the master nodes, and we need a way to collect and forward them to Qradar. For that we are going to deploy the two operators below.
Default configurations can be used. Simply install the operator and don't deploy any instance of it yet.

1. From the Openshift Console, go to the operator hub and deploy the **OpenShift Elasticsearch Operator** and **Cluster Logging Operator**

<br>

### 2.3 Deploying a Logging Operator instance
1. From the Openshift Console, go to Installed Operators and select the *Cluster Logging Operator*.
2. Click on *Cluster Logging* and then *Create Cluster Logging* to deploy a Cluster Logging Instance.
3. Switch to yaml view, and paste the following content. **Please note to specify your own storage class on the storageClassName field**. Feel free to modify the remaining values as you see fit.


```
apiVersion: logging.openshift.io/v1
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  collection:
    logs:
      fluentd: {}
      type: fluentd
  forwarder:
    fluentd:
      buffer:
        flushThreadCount: 4
        flushMode: immediate
        flushInterval: 30s
        overflowAction: drop_oldest_chunk
  logStore:
    elasticsearch:
      storage:
        storageClassName: gp2
        size: 400G
      nodeCount: 3
      redundancyPolicy: SingleRedundancy
    retentionPolicy:
      application:
        maxAge: 1d
      audit:
        maxAge: 1d
        pruneNamespacesInterval: 1d
    type: elasticsearch
  visualization:
    kibana:
      replicas: 1
    type: kibana
  managementState: Managed
  ```

4. Once this is applied, the following pods will be created in the openshift-logging namespace. The amount will vary depend on your own defined configurations. Make sure they are all ready before proceeding to the next step.

-cluster-logging-operator-cb795f8dc-xkckc

-elasticsearch-cdm-b3nqzchd-1-5c6797-67kfz

-elasticsearch-cdm-b3nqzchd-2-6657f4-wtprv

-elasticsearch-cdm-b3nqzchd-3-588c65-clg7g

-fluentd-2c7dg

-fluentd-9z7kk

-fluentd-br7r2

-fluentd-fn2sb

-fluentd-pb2f8

-fluentd-zqgqx

-kibana-7fb4fd4cc9-bvt4p

<br>

### 2.4 Deploying a ClusterLogForwarder Instace
Here we will specify the forwarding settings. You will need to have ready the hostname/IP/port of your Qradar.

1. At the Openshift console, go to Installed Operators
2. Go to *Cluster Logging* and then *Create Cluster Log Forwarder* to deploy an instance.
3. Switch to yaml, and paste the content below. **Define your own Qradar hostname/IP/port**

```
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance 
  namespace: openshift-logging
spec:
  outputs:
    - name: qradar
      syslog:
        appName: MyCluster
        facility: user
        msgID: mymsg
        procID: myproc
        rfc: RFC5424
        severity: debug
      type: syslog
      url: 'udp://qradar.example.com:514'
  pipelines:
    - inputRefs:
        - audit
      name: qradar-in
      outputRefs:
        - qradar
```   

4. Once this configuration is created, the *collector* pods from openshift-logging will be restarted. After they come back up you should be able to see events flowing into your Qradar.

## 3. Qradar Optional Configurations
### 3.1 Refining the DSM
If might be that not all the properties of an Event are mapped automatically in Qradar. But don't worry, we can easily add the ones we need by modifying the Kubernetes DSM, following the procedure below:

1. On the Qradar console, go to Log Activity.
2. Click on an event you want to modify. Right click on it and Open the DSM Editor.

![image](https://user-images.githubusercontent.com/75438200/165960266-6a7b2622-0731-45a9-84b5-c5648c956d69.png)

3. Click on the plus icon to create a new Custom Property.
4. Name it. In this example I'm creating a property called *PodName* with the field type *text*.
5. Select the new property and click Edit to map it to the content of the event. You can do that with JSON syntax as per the example below.

/"requestObject"/"metadata"/"name"

![image](https://user-images.githubusercontent.com/75438200/165961118-54b40ea6-b3cf-47dc-bd89-afe2165491f9.png)

![image](https://user-images.githubusercontent.com/75438200/165962626-cee66fe2-adcc-40f1-ba32-6a64bd0f0d17.png)


<br>

### 3.2 Estimating EPS consumption
Adding a new log source to Qradar will increment the EPS consumption of the device, and with that you might need to plan for more compute, more licenses or storage, for example. <br>
Estimating in advance the amount of EPS your Openshift cluster will generate can be challenging, but you can at least measure that number once the events are flowing.
For example, you could run a search in your Qradar with 2 filters. One will be the log source type *Kubernetes Audit* and 2 a valid representative time window (an hour, a day, a week). In the example below, we can see that 425 events were generated in 1 hour, which is about 0.1 event per second. But then again, my environment is a lab with little activity. Each Openshift cluster will be different and this number will vary significantly. 

![image](https://user-images.githubusercontent.com/75438200/165961882-cde20a5e-9a27-49e1-97d8-d90036180888.png)




